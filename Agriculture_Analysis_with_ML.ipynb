{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_Ku73dzClWw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Set dataset path (replace with your actual path)\n",
        "dataset_path = kagglehub.dataset_download(\"nirmalsankalana/rice-leaf-disease-image\")\n",
        "\n",
        "# Check if dataset path is valid\n",
        "if not os.path.exists(dataset_path):\n",
        "    raise ValueError(\"Dataset path does not exist.\")\n",
        "\n",
        "# Define parameters\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Load dataset and create labels (assuming images are organized in folders by disease type)\n",
        "diseases = ['Bacterial_Blight', 'Blast', 'Brown_Spot', 'Tungro']\n",
        "data = []\n",
        "\n",
        "for disease in diseases:\n",
        "    disease_path = os.path.join(dataset_path, disease)\n",
        "\n",
        "    # Check if disease directory exists\n",
        "    if not os.path.exists(disease_path):\n",
        "        print(f\"Warning: Disease directory '{disease_path}' does not exist.\")\n",
        "        continue\n",
        "\n",
        "    images = os.listdir(disease_path)\n",
        "\n",
        "    for img in images:\n",
        "        data.append((os.path.join(disease_path, img), disease))\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data, columns=['image_path', 'label'])\n",
        "\n",
        "# Print total images and class distribution for debugging\n",
        "print(\"Total images loaded:\", len(df))\n",
        "print(\"Class distribution:\\n\", df['label'].value_counts())\n",
        "\n",
        "# Train-Test Split: Keep first 100 even-numbered images for each disease in test set\n",
        "test_data = []\n",
        "train_data = []\n",
        "\n",
        "for disease in diseases:\n",
        "    disease_images = df[df['label'] == disease]\n",
        "\n",
        "    # Ensure there are enough images to select from\n",
        "    if len(disease_images) < 100:\n",
        "        print(f\"Warning: Not enough images for {disease}. Available: {len(disease_images)}\")\n",
        "        continue\n",
        "\n",
        "    even_images = disease_images.iloc[::2].head(100)  # Select first 100 even-indexed images\n",
        "\n",
        "    test_data.append(even_images)\n",
        "    train_data.append(disease_images.drop(even_images.index))\n",
        "\n",
        "if not test_data or not train_data:\n",
        "    raise ValueError(\"No valid data found for training or testing.\")\n",
        "\n",
        "test_df = pd.concat(test_data)\n",
        "train_df = pd.concat(train_data)\n",
        "\n",
        "# Data Generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='image_path',\n",
        "    y_col='label',\n",
        "    target_size=image_size,\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size)\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    x_col='image_path',\n",
        "    y_col='label',\n",
        "    target_size=image_size,\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size)\n",
        "\n",
        "# Determine the number of classes dynamically\n",
        "num_classes = len(df['label'].unique())  # Dynamically set number of classes\n",
        "\n",
        "# Transfer Learning with VGG16\n",
        "def create_vgg16_model():\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))  # Use num_classes instead of len(diseases)\n",
        "\n",
        "    # Freeze the base model layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    return model\n",
        "\n",
        "vgg16_model = create_vgg16_model()\n",
        "vgg16_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train VGG16 Model\n",
        "history_vgg16 = vgg16_model.fit(train_generator, validation_data=test_generator, epochs=1)\n",
        "\n",
        "# Custom CNN Model\n",
        "def create_custom_cnn():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolutional Layers\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(num_classes, activation='softmax'))  # Use num_classes instead of len(diseases)\n",
        "\n",
        "    return model\n",
        "\n",
        "custom_cnn_model = create_custom_cnn()\n",
        "custom_cnn_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train Custom CNN Model\n",
        "history_custom_cnn = custom_cnn_model.fit(train_generator, validation_data=test_generator, epochs=1)\n",
        "\n",
        "# Plotting Results\n",
        "def plot_history(history_vgg16, history_custom_cnn):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Accuracy Plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history_vgg16.history['accuracy'], label='VGG16 Train')\n",
        "    plt.plot(history_vgg16.history['val_accuracy'], label='VGG16 Validation')\n",
        "\n",
        "    plt.plot(history_custom_cnn.history['accuracy'], label='Custom CNN Train')\n",
        "    plt.plot(history_custom_cnn.history['val_accuracy'], label='Custom CNN Validation')\n",
        "\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history_vgg16.history['loss'], label='VGG16 Train')\n",
        "    plt.plot(history_vgg16.history['val_loss'], label='VGG16 Validation')\n",
        "\n",
        "    plt.plot(history_custom_cnn.history['loss'], label='Custom CNN Train')\n",
        "    plt.plot(history_custom_cnn.history['val_loss'], label='Custom CNN Validation')\n",
        "\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plot_history(history_vgg16, history_custom_cnn)"
      ]
    }
  ]
}